{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from importlib import reload\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "os.chdir(r'C:\\Users\\kamil\\Documents\\PredictModel\\data-science-salaries-project')\n",
    "\n",
    "processed_train= r'data-science-salaries-project\\data\\processed\\processed_data_train.csv'\n",
    "processed_test= r'data-science-salaries-project\\data\\processed\\processed_data_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(processed_train)\n",
    "test_data = pd.read_csv(processed_test)\n",
    "\n",
    "# MAP QUALITY TO 0-6\n",
    "mapping = {3: 0, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5, 9: 6}\n",
    "train_data['quality'] = train_data['quality'].map(mapping)\n",
    "test_data['quality'] = test_data['quality'].map(mapping)\n",
    "\n",
    "X_train = train_data.drop('quality', axis=1)\n",
    "y_train = train_data['quality']\n",
    "\n",
    "X_test = test_data.drop('quality', axis=1)\n",
    "y_test = test_data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.LR_hyperparams_search\n",
    "import functions.xgboost_hyperparams_search\n",
    "import functions.MLPC_hyperparams_search\n",
    "\n",
    "reload(functions.LR_hyperparams_search)  # To ensure the latest version is loaded\n",
    "reload(functions.xgboost_hyperparams_search) \n",
    "reload(functions.MLPC_hyperparams_search)\n",
    "\n",
    "from functions.xgboost_hyperparams_search import xgboost_hyperparams_search\n",
    "from functions.LR_hyperparams_search import LR_hyperparams_search\n",
    "from functions.MLPC_hyperparams_search import MLP_hyperparams_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8f2d1662b24b1487a7167fb8b13827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', index=2, options=('Logistic Regression', 'XGBoost', 'MLP Classifier'), value='Mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250a2c356846413bb6633ee2a38a9e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Search type:', index=1, options=('grid', 'random', 'optuna'), value='random')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e9fa3de11440c1a9dc0d99e96f9640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=6, continuous_update=False, description='n_trials:', min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696164825977451896fbced11d6a0ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Start Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the best hyperparameters for the MLP Classifier model using random search.\n",
      " Wait a moment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamil\\Documents\\PredictModel\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'lbfgs', 'momentum': np.float64(0.99), 'max_iter': 500, 'learning_rate_init': np.float64(0.00021544346900318845), 'hidden_layer_sizes': (100, 50), 'batch_size': 128, 'alpha': np.float64(0.03593813663804626), 'activation': 'relu'}\n",
      "Accuracy: 0.5638\n",
      "Best MLP Classifier Model: MLPClassifier(alpha=np.float64(0.03593813663804626), batch_size=128,\n",
      "              hidden_layer_sizes=(100, 50),\n",
      "              learning_rate_init=np.float64(0.00021544346900318845),\n",
      "              max_iter=500, momentum=np.float64(0.99), random_state=42,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamil\\Documents\\PredictModel\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# widgets \n",
    "\n",
    "model_widget = widgets.Dropdown(\n",
    "    options=['Logistic Regression', 'XGBoost', 'MLP Classifier'],\n",
    "    value='Logistic Regression',\n",
    "    description='Model:'\n",
    ")\n",
    "\n",
    "search_type_widget = widgets.Dropdown(\n",
    "    options=['grid', 'random', 'optuna'],\n",
    "    value='random',\n",
    "    description='Search type:'\n",
    ")\n",
    "\n",
    "n_trials_widget = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='n_trials:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Button widget\n",
    "search_button = widgets.Button(description=\"Start Search\")\n",
    "\n",
    "# Definition of the function that will be called when the button is clicked\n",
    "def hyperparameter_search(model_type, type_of_search, n_trials):\n",
    "    if model_type == 'Logistic Regression':\n",
    "        LR_best_model = LR_hyperparams_search(X_train, y_train, X_test, y_test, n_trials=n_trials, type_of_search=type_of_search)\n",
    "        print(f\"Best Logistic Regression Model: {LR_best_model}\")\n",
    "    elif model_type == 'XGBoost':\n",
    "        XGBoost_best_model = xgboost_hyperparams_search(X_train, y_train, X_test, y_test, n_trials=n_trials, type_of_search=type_of_search)\n",
    "        print(f\"Best XGBoost Model: {XGBoost_best_model}\")\n",
    "\n",
    "    elif model_type == 'MLP Classifier':\n",
    "        MLP_best_model = MLP_hyperparams_search(X_train, y_train, X_test, y_test, n_trials=n_trials, type_of_search=type_of_search)\n",
    "        print(f\"Best MLP Classifier Model: {MLP_best_model}\")\n",
    "    else:\n",
    "        print(\"Unknown model type\")\n",
    "\n",
    "\n",
    "def on_search_button_click(b):\n",
    "    clear_output(wait=True)  # Clear the output of the current output cell receiving output\n",
    "    display(model_widget, search_type_widget, n_trials_widget, search_button) # show again the widgets\n",
    "    model_type = model_widget.value\n",
    "    search_type = search_type_widget.value\n",
    "    n_trials = n_trials_widget.value\n",
    "    print(f\"Searching for the best hyperparameters for the {model_type} model using {search_type} search.\\n Wait a moment...\")\n",
    "    \n",
    "    # Start the hyperparameter search\n",
    "    hyperparameter_search(model_type, search_type, n_trials)\n",
    "\n",
    "# Assign the event handler to the button\n",
    "search_button.on_click(on_search_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(model_widget, search_type_widget, n_trials_widget, search_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "Precision: 0.6662\n",
      "Recall: 0.6662\n",
      "F1 Score: 0.6662\n",
      "Accuracy: 0.6662\n",
      "Mean Squared Error (MSE): 0.4700\n",
      "Mean Absolute Error (MAE): 0.3762\n",
      "R-squared (R2): 0.3886\n",
      "\n",
      "Model: MLP\n",
      "Precision: 0.5677\n",
      "Recall: 0.5677\n",
      "F1 Score: 0.5677\n",
      "Accuracy: 0.5677\n",
      "Mean Squared Error (MSE): 0.5977\n",
      "Mean Absolute Error (MAE): 0.4838\n",
      "R-squared (R2): 0.2225\n",
      "\n",
      "Model: Logistic_Regression\n",
      "Precision: 0.5192\n",
      "Recall: 0.5192\n",
      "F1 Score: 0.5192\n",
      "Accuracy: 0.5192\n",
      "Mean Squared Error (MSE): 0.6908\n",
      "Mean Absolute Error (MAE): 0.5462\n",
      "R-squared (R2): 0.1014\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamil\\Documents\\PredictModel\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definition of models to train\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"Logistic_Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Training and evaluation of models\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculating metrics\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R-squared (R2): {r2:.4f}\\n\")\n",
    "\n",
    "    # # Cross-validation\n",
    "    # cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    # print(f\"Cross-validation Scores (Accuracy): {[score for score in cv_scores]}\\n\")\n",
    "    # print(f\"Mean Accuracy from Cross-validation: {cv_scores.mean():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.4314\n",
      "Mean Absolute Error (MAE): 0.4705\n",
      "R-squared (R2): 0.4388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Train the XGBRegressor model\n",
    "xgb_regressor = xgb.XGBRegressor()\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
